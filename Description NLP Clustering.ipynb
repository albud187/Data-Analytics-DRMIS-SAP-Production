{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "import spacy\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv1D, MaxPool1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"../Data-Analytics-DRMIS-SAP-Production-DATA/\"\n",
    "\n",
    "df = pd.read_csv(data_folder + 'LAV 6.csv', encoding = 'ISO-8859-1', index_col = 1).reset_index(drop = False)\n",
    "#re-download df with MaintActivityType\n",
    "df = df[df['Order Type']=='L001'].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df['Description'].astype(str).tolist()\n",
    "token = Tokenizer()\n",
    "token.fit_on_texts(text)\n",
    "vocab = len(token.index_word) + 1\n",
    "encoded_text = token.texts_to_sequences(text)\n",
    "\n",
    "max_length = max([len(x) for x in encoded_text])\n",
    "\n",
    "token_dict = token.__dict__\n",
    "word_list1 = list(token_dict['index_word'].values())\n",
    "drop_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\olfoa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(1,max_length+1):\n",
    "    df[str(i)+ ' encoded word'] = [0]*len(df)\n",
    "    for n in range(len(df)):\n",
    "        try:\n",
    "            df[str(i)+ ' encoded word'][n] = encoded_text[n][i-1]\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_words_lists =[]\n",
    "\n",
    "for i in range(1,13):\n",
    "    encoded_words_lists.append(str(i)+ ' encoded word')\n",
    "ready_df = df[['Order','Description','Total planned costs', 'PM Orders planned hours']+encoded_words_lists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Order Type',\n",
       " 'Created on',\n",
       " 'Basic start date',\n",
       " 'Description',\n",
       " 'Total planned costs',\n",
       " 'PM Orders planned hours',\n",
       " 'PM Orders actual hours',\n",
       " 'Tail Number / Identifier',\n",
       " 'User Status',\n",
       " 'Main work center',\n",
       " 'Vehicle Type',\n",
       " 'Work Type',\n",
       " 'Work Type Text',\n",
       " 'Scheduled Fin. Time',\n",
       " 'Scheduled finish',\n",
       " 'Scheduled start',\n",
       " 'Priority',\n",
       " 'Priority text',\n",
       " 'Priority type',\n",
       " 'PM order',\n",
       " 'Maintenance item',\n",
       " 'MaintActivityType',\n",
       " 'MaintActivityType.1',\n",
       " 'Level',\n",
       " 'Level of work',\n",
       " 'License plate number',\n",
       " 'Actual Finish Time',\n",
       " 'Actual Order Finish Date',\n",
       " 'Actual release date',\n",
       " 'Actual start date',\n",
       " 'ActualStartTime',\n",
       " 'Available from Date',\n",
       " 'Available from time',\n",
       " 'Available to date',\n",
       " 'Available to time',\n",
       " 'Basic finish date',\n",
       " 'Estimated costs',\n",
       " 'Flow through costs',\n",
       " 'Maintenance strategy',\n",
       " '1 encoded word',\n",
       " '2 encoded word',\n",
       " '3 encoded word',\n",
       " '4 encoded word',\n",
       " '5 encoded word',\n",
       " '6 encoded word',\n",
       " '7 encoded word',\n",
       " '8 encoded word',\n",
       " '9 encoded word',\n",
       " '10 encoded word',\n",
       " '11 encoded word',\n",
       " '12 encoded word']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      NaN\n",
       "1      NaN\n",
       "2      NaN\n",
       "3      NaN\n",
       "4      NaN\n",
       "        ..\n",
       "9974   NaN\n",
       "9975   NaN\n",
       "9976   NaN\n",
       "9977   NaN\n",
       "9978   NaN\n",
       "Name: PM order, Length: 9979, dtype: float64"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['word_counts', 'word_docs', 'filters', 'split', 'lower', 'num_words', 'document_count', 'char_level', 'oov_token', 'index_docs', 'word_index', 'index_word'])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_dict = token.__dict__\n",
    "word_list1 = list(token_dict['index_word'].values())\n",
    "drop_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove:\n",
    "- non words (codes, ect)\n",
    "- numbers\n",
    "- stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy\n",
    "nlp = spacy.load('en_vectors_web_lg')\n",
    "def similarityy(x,y):\n",
    "    return(nlp(x).similarity(nlp(y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove numbers\n",
    "for i in range(len(word_list1)):\n",
    "    try:\n",
    "        if type(float(word_list1[i])) == type(1.0):\n",
    "            word_list1.pop(i)\n",
    "    \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "for i in range(len(word_list1)):\n",
    "    try:\n",
    "        if type(float(word_list1[i])) == type(1):\n",
    "            word_list1.pop(i)\n",
    "    \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for i in range(len(word_list1)):\n",
    "    try:\n",
    "        if len(word_list1[i]) <= 2:\n",
    "            word_list1.pop(i)\n",
    "    \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "#remove non words\n",
    "for i in range(len(word_list1)):\n",
    "    try:\n",
    "        if similarityy(word_list1[i], 'vehicle') < 0.15:\n",
    "            word_list1.pop(i)\n",
    "    except:\n",
    "        pass\n",
    "for i in range(len(word_list1)):\n",
    "    try:\n",
    "        if type(float(word_list1[i])) == type(1.0):\n",
    "            word_list1.pop(i)\n",
    "    \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "for i in range(len(word_list1)):\n",
    "    try:\n",
    "        if type(float(word_list1[i])) == type(1):\n",
    "            word_list1.pop(i)\n",
    "    \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for i in range(len(word_list1)):\n",
    "    try:\n",
    "        if len(word_list1[i]) <= 2:\n",
    "            word_list1.pop(i)\n",
    "    \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "word_counts = dict(token.__dict__['word_counts'])\n",
    "real_words = {}\n",
    "for word in word_list1:\n",
    "    real_words[word] = word_counts[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "991"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(real_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A-2VP-03403-LAV 6- POWER PACK N/S'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Description'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order Type</th>\n",
       "      <th>Created on</th>\n",
       "      <th>Basic start date</th>\n",
       "      <th>Description</th>\n",
       "      <th>Total planned costs</th>\n",
       "      <th>PM Orders planned hours</th>\n",
       "      <th>PM Orders actual hours</th>\n",
       "      <th>Tail Number / Identifier</th>\n",
       "      <th>User Status</th>\n",
       "      <th>Main work center</th>\n",
       "      <th>...</th>\n",
       "      <th>Actual start date</th>\n",
       "      <th>ActualStartTime</th>\n",
       "      <th>Available from Date</th>\n",
       "      <th>Available from time</th>\n",
       "      <th>Available to date</th>\n",
       "      <th>Available to time</th>\n",
       "      <th>Basic finish date</th>\n",
       "      <th>Estimated costs</th>\n",
       "      <th>Flow through costs</th>\n",
       "      <th>Maintenance strategy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>L001</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>A-2VP-03403-LAV 6- POWER PACK N/S</td>\n",
       "      <td>172,711.02</td>\n",
       "      <td>20.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2011-03403</td>\n",
       "      <td>OAPP HPR1</td>\n",
       "      <td>XWBB---2</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-04-25</td>\n",
       "      <td>12:00:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12:00:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12:00:00 AM</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>L001</td>\n",
       "      <td>2016-04-12</td>\n",
       "      <td>2016-04-12</td>\n",
       "      <td>A-2VP-03427-LAV 6-Front Left Tire</td>\n",
       "      <td>8,214.99</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2011-03427</td>\n",
       "      <td>OAPP</td>\n",
       "      <td>XWBB---2</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-04-14</td>\n",
       "      <td>12:00:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12:00:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12:00:00 AM</td>\n",
       "      <td>2016-04-12</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>L001</td>\n",
       "      <td>2016-04-12</td>\n",
       "      <td>2016-04-12</td>\n",
       "      <td>A-2VP-03452-LAV 6-Hydrop/Front tire N/S</td>\n",
       "      <td>9,469.83</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2011-03452</td>\n",
       "      <td>OAPP</td>\n",
       "      <td>XWBB---2</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-04-18</td>\n",
       "      <td>12:00:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12:00:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12:00:00 AM</td>\n",
       "      <td>2016-04-12</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>L001</td>\n",
       "      <td>2019-04-10</td>\n",
       "      <td>2019-04-10</td>\n",
       "      <td>2VP - LAV6 - 03409 - Replace PP</td>\n",
       "      <td>173,727.17</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2011-03409</td>\n",
       "      <td>OAPP</td>\n",
       "      <td>XWBB---2</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-04-10</td>\n",
       "      <td>12:00:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12:00:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12:00:00 AM</td>\n",
       "      <td>2019-04-10</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>L001</td>\n",
       "      <td>2019-04-08</td>\n",
       "      <td>2019-04-08</td>\n",
       "      <td>2VP - LAV6 - 03411 - L1 STRUT NS</td>\n",
       "      <td>9,356.58</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2011-03411</td>\n",
       "      <td>OAPP HPR1</td>\n",
       "      <td>XWBB---2</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-04-08</td>\n",
       "      <td>12:00:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12:00:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12:00:00 AM</td>\n",
       "      <td>2019-04-08</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13666</td>\n",
       "      <td>L001</td>\n",
       "      <td>2016-05-27</td>\n",
       "      <td>2016-08-23</td>\n",
       "      <td>LAV 6.0 INSPECTION REPARATION - 03381</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-03381</td>\n",
       "      <td>OAPP</td>\n",
       "      <td>202PROD</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12:00:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12:00:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12:00:00 AM</td>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13667</td>\n",
       "      <td>L001</td>\n",
       "      <td>2016-05-27</td>\n",
       "      <td>2016-05-27</td>\n",
       "      <td>LAV 6.0 INSPECTION REPARATION - 03383</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-03383</td>\n",
       "      <td>OAPP</td>\n",
       "      <td>202PROD</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12:00:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12:00:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12:00:00 AM</td>\n",
       "      <td>2016-05-27</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13668</td>\n",
       "      <td>L001</td>\n",
       "      <td>2017-02-06</td>\n",
       "      <td>2017-02-06</td>\n",
       "      <td>LAV 6.0 Engine ECM Flash</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-03492</td>\n",
       "      <td>OAPP</td>\n",
       "      <td>202PROD</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12:00:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12:00:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12:00:00 AM</td>\n",
       "      <td>2017-02-06</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13669</td>\n",
       "      <td>L001</td>\n",
       "      <td>2018-02-26</td>\n",
       "      <td>2018-07-10</td>\n",
       "      <td>INSTALLATION BLINDAGE</td>\n",
       "      <td>198,383.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-03868</td>\n",
       "      <td>OAPP</td>\n",
       "      <td>202PROD</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12:00:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12:00:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12:00:00 AM</td>\n",
       "      <td>2018-10-19</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13670</td>\n",
       "      <td>L001</td>\n",
       "      <td>2018-02-26</td>\n",
       "      <td>2018-08-28</td>\n",
       "      <td>INSTALLATION BLINDAGE</td>\n",
       "      <td>198,383.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-03870</td>\n",
       "      <td>OAPP</td>\n",
       "      <td>202PROD</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12:00:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12:00:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12:00:00 AM</td>\n",
       "      <td>2018-10-19</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9979 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Order Type  Created on Basic start date  \\\n",
       "0           L001  2016-04-24       2016-04-24   \n",
       "1           L001  2016-04-12       2016-04-12   \n",
       "2           L001  2016-04-12       2016-04-12   \n",
       "3           L001  2019-04-10       2019-04-10   \n",
       "4           L001  2019-04-08       2019-04-08   \n",
       "...          ...         ...              ...   \n",
       "13666       L001  2016-05-27       2016-08-23   \n",
       "13667       L001  2016-05-27       2016-05-27   \n",
       "13668       L001  2017-02-06       2017-02-06   \n",
       "13669       L001  2018-02-26       2018-07-10   \n",
       "13670       L001  2018-02-26       2018-08-28   \n",
       "\n",
       "                                   Description Total planned costs  \\\n",
       "0            A-2VP-03403-LAV 6- POWER PACK N/S          172,711.02   \n",
       "1            A-2VP-03427-LAV 6-Front Left Tire            8,214.99   \n",
       "2      A-2VP-03452-LAV 6-Hydrop/Front tire N/S            9,469.83   \n",
       "3              2VP - LAV6 - 03409 - Replace PP          173,727.17   \n",
       "4             2VP - LAV6 - 03411 - L1 STRUT NS            9,356.58   \n",
       "...                                        ...                 ...   \n",
       "13666    LAV 6.0 INSPECTION REPARATION - 03381                   0   \n",
       "13667    LAV 6.0 INSPECTION REPARATION - 03383                   0   \n",
       "13668                 LAV 6.0 Engine ECM Flash                   0   \n",
       "13669                    INSTALLATION BLINDAGE          198,383.79   \n",
       "13670                    INSTALLATION BLINDAGE          198,383.79   \n",
       "\n",
       "       PM Orders planned hours  PM Orders actual hours  \\\n",
       "0                         20.0                    55.0   \n",
       "1                          8.0                     8.0   \n",
       "2                         20.0                    10.0   \n",
       "3                         19.0                    19.0   \n",
       "4                         15.0                    12.0   \n",
       "...                        ...                     ...   \n",
       "13666                      0.0                     0.0   \n",
       "13667                      0.0                     0.0   \n",
       "13668                      0.0                     0.0   \n",
       "13669                      0.0                     0.0   \n",
       "13670                      0.0                     0.0   \n",
       "\n",
       "      Tail Number / Identifier User Status Main work center  ...  \\\n",
       "0                   2011-03403   OAPP HPR1         XWBB---2  ...   \n",
       "1                   2011-03427        OAPP         XWBB---2  ...   \n",
       "2                   2011-03452        OAPP         XWBB---2  ...   \n",
       "3                   2011-03409        OAPP         XWBB---2  ...   \n",
       "4                   2011-03411   OAPP HPR1         XWBB---2  ...   \n",
       "...                        ...         ...              ...  ...   \n",
       "13666               2011-03381        OAPP          202PROD  ...   \n",
       "13667               2011-03383        OAPP          202PROD  ...   \n",
       "13668               2011-03492        OAPP          202PROD  ...   \n",
       "13669               2016-03868        OAPP          202PROD  ...   \n",
       "13670               2016-03870        OAPP          202PROD  ...   \n",
       "\n",
       "      Actual start date  ActualStartTime  Available from Date  \\\n",
       "0            2016-04-25      12:00:00 AM                  NaN   \n",
       "1            2016-04-14      12:00:00 AM                  NaN   \n",
       "2            2016-04-18      12:00:00 AM                  NaN   \n",
       "3            2019-04-10      12:00:00 AM                  NaN   \n",
       "4            2019-04-08      12:00:00 AM                  NaN   \n",
       "...                 ...              ...                  ...   \n",
       "13666               NaN      12:00:00 AM                  NaN   \n",
       "13667               NaN      12:00:00 AM                  NaN   \n",
       "13668               NaN      12:00:00 AM                  NaN   \n",
       "13669               NaN      12:00:00 AM                  NaN   \n",
       "13670               NaN      12:00:00 AM                  NaN   \n",
       "\n",
       "      Available from time Available to date Available to time  \\\n",
       "0             12:00:00 AM               NaN       12:00:00 AM   \n",
       "1             12:00:00 AM               NaN       12:00:00 AM   \n",
       "2             12:00:00 AM               NaN       12:00:00 AM   \n",
       "3             12:00:00 AM               NaN       12:00:00 AM   \n",
       "4             12:00:00 AM               NaN       12:00:00 AM   \n",
       "...                   ...               ...               ...   \n",
       "13666         12:00:00 AM               NaN       12:00:00 AM   \n",
       "13667         12:00:00 AM               NaN       12:00:00 AM   \n",
       "13668         12:00:00 AM               NaN       12:00:00 AM   \n",
       "13669         12:00:00 AM               NaN       12:00:00 AM   \n",
       "13670         12:00:00 AM               NaN       12:00:00 AM   \n",
       "\n",
       "       Basic finish date Estimated costs Flow through costs  \\\n",
       "0             2016-04-24               0                NaN   \n",
       "1             2016-04-12               0                NaN   \n",
       "2             2016-04-12               0                NaN   \n",
       "3             2019-04-10               0                NaN   \n",
       "4             2019-04-08               0                NaN   \n",
       "...                  ...             ...                ...   \n",
       "13666         2017-05-01               0                NaN   \n",
       "13667         2016-05-27               0                NaN   \n",
       "13668         2017-02-06               0                NaN   \n",
       "13669         2018-10-19               0                NaN   \n",
       "13670         2018-10-19               0                NaN   \n",
       "\n",
       "       Maintenance strategy  \n",
       "0                       NaN  \n",
       "1                       NaN  \n",
       "2                       NaN  \n",
       "3                       NaN  \n",
       "4                       NaN  \n",
       "...                     ...  \n",
       "13666                   NaN  \n",
       "13667                   NaN  \n",
       "13668                   NaN  \n",
       "13669                   NaN  \n",
       "13670                   NaN  \n",
       "\n",
       "[9979 rows x 39 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clustering should combine features from description, as well as PM orders planned hours, Total planned costs, order type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Tokenizer in module keras_preprocessing.text object:\n",
      "\n",
      "class Tokenizer(builtins.object)\n",
      " |  Text tokenization utility class.\n",
      " |  \n",
      " |  This class allows to vectorize a text corpus, by turning each\n",
      " |  text into either a sequence of integers (each integer being the index\n",
      " |  of a token in a dictionary) or into a vector where the coefficient\n",
      " |  for each token could be binary, based on word count, based on tf-idf...\n",
      " |  \n",
      " |  # Arguments\n",
      " |      num_words: the maximum number of words to keep, based\n",
      " |          on word frequency. Only the most common `num_words-1` words will\n",
      " |          be kept.\n",
      " |      filters: a string where each element is a character that will be\n",
      " |          filtered from the texts. The default is all punctuation, plus\n",
      " |          tabs and line breaks, minus the `'` character.\n",
      " |      lower: boolean. Whether to convert the texts to lowercase.\n",
      " |      split: str. Separator for word splitting.\n",
      " |      char_level: if True, every character will be treated as a token.\n",
      " |      oov_token: if given, it will be added to word_index and used to\n",
      " |          replace out-of-vocabulary words during text_to_sequence calls\n",
      " |  \n",
      " |  By default, all punctuation is removed, turning the texts into\n",
      " |  space-separated sequences of words\n",
      " |  (words maybe include the `'` character). These sequences are then\n",
      " |  split into lists of tokens. They will then be indexed or vectorized.\n",
      " |  \n",
      " |  `0` is a reserved index that won't be assigned to any word.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ', char_level=False, oov_token=None, document_count=0, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit_on_sequences(self, sequences)\n",
      " |      Updates internal vocabulary based on a list of sequences.\n",
      " |      \n",
      " |      Required before using `sequences_to_matrix`\n",
      " |      (if `fit_on_texts` was never called).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          sequences: A list of sequence.\n",
      " |              A \"sequence\" is a list of integer word indices.\n",
      " |  \n",
      " |  fit_on_texts(self, texts)\n",
      " |      Updates internal vocabulary based on a list of texts.\n",
      " |      \n",
      " |      In the case where texts contains lists,\n",
      " |      we assume each entry of the lists to be a token.\n",
      " |      \n",
      " |      Required before using `texts_to_sequences` or `texts_to_matrix`.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          texts: can be a list of strings,\n",
      " |              a generator of strings (for memory-efficiency),\n",
      " |              or a list of list of strings.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the tokenizer configuration as Python dictionary.\n",
      " |      The word count dictionaries used by the tokenizer get serialized\n",
      " |      into plain JSON, so that the configuration can be read by other\n",
      " |      projects.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A Python dictionary with the tokenizer configuration.\n",
      " |  \n",
      " |  sequences_to_matrix(self, sequences, mode='binary')\n",
      " |      Converts a list of sequences into a Numpy matrix.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          sequences: list of sequences\n",
      " |              (a sequence is a list of integer word indices).\n",
      " |          mode: one of \"binary\", \"count\", \"tfidf\", \"freq\"\n",
      " |      \n",
      " |      # Returns\n",
      " |          A Numpy matrix.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: In case of invalid `mode` argument,\n",
      " |              or if the Tokenizer requires to be fit to sample data.\n",
      " |  \n",
      " |  sequences_to_texts(self, sequences)\n",
      " |      Transforms each sequence into a list of text.\n",
      " |      \n",
      " |      Only top `num_words-1` most frequent words will be taken into account.\n",
      " |      Only words known by the tokenizer will be taken into account.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          sequences: A list of sequences (list of integers).\n",
      " |      \n",
      " |      # Returns\n",
      " |          A list of texts (strings)\n",
      " |  \n",
      " |  sequences_to_texts_generator(self, sequences)\n",
      " |      Transforms each sequence in `sequences` to a list of texts(strings).\n",
      " |      \n",
      " |      Each sequence has to a list of integers.\n",
      " |      In other words, sequences should be a list of sequences\n",
      " |      \n",
      " |      Only top `num_words-1` most frequent words will be taken into account.\n",
      " |      Only words known by the tokenizer will be taken into account.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          sequences: A list of sequences.\n",
      " |      \n",
      " |      # Yields\n",
      " |          Yields individual texts.\n",
      " |  \n",
      " |  texts_to_matrix(self, texts, mode='binary')\n",
      " |      Convert a list of texts to a Numpy matrix.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          texts: list of strings.\n",
      " |          mode: one of \"binary\", \"count\", \"tfidf\", \"freq\".\n",
      " |      \n",
      " |      # Returns\n",
      " |          A Numpy matrix.\n",
      " |  \n",
      " |  texts_to_sequences(self, texts)\n",
      " |      Transforms each text in texts to a sequence of integers.\n",
      " |      \n",
      " |      Only top `num_words-1` most frequent words will be taken into account.\n",
      " |      Only words known by the tokenizer will be taken into account.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          texts: A list of texts (strings).\n",
      " |      \n",
      " |      # Returns\n",
      " |          A list of sequences.\n",
      " |  \n",
      " |  texts_to_sequences_generator(self, texts)\n",
      " |      Transforms each text in `texts` to a sequence of integers.\n",
      " |      \n",
      " |      Each item in texts can also be a list,\n",
      " |      in which case we assume each item of that list to be a token.\n",
      " |      \n",
      " |      Only top `num_words-1` most frequent words will be taken into account.\n",
      " |      Only words known by the tokenizer will be taken into account.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          texts: A list of texts (strings).\n",
      " |      \n",
      " |      # Yields\n",
      " |          Yields individual sequences.\n",
      " |  \n",
      " |  to_json(self, **kwargs)\n",
      " |      Returns a JSON string containing the tokenizer configuration.\n",
      " |      To load a tokenizer from a JSON string, use\n",
      " |      `keras.preprocessing.text.tokenizer_from_json(json_string)`.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          **kwargs: Additional keyword arguments\n",
      " |              to be passed to `json.dumps()`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A JSON string containing the tokenizer configuration.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(help(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create ranges of days WIP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
