{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "import spacy\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv1D, MaxPool1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"../Data-Analytics-DRMIS-SAP-Production-DATA/\"\n",
    "\n",
    "df = pd.read_csv(data_folder + 'LAV 6.csv', encoding = 'ISO-8859-1', index_col = 0).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-145279618ebd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Description'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mvocab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_word\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mencoded_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\olfoa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras_preprocessing\\text.py\u001b[0m in \u001b[0;36mfit_on_texts\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m    221\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m                                             self.split)\n\u001b[0m\u001b[0;32m    224\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mseq\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_counts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\olfoa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras_preprocessing\\text.py\u001b[0m in \u001b[0;36mtext_to_word_sequence\u001b[1;34m(text, filters, lower, split)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \"\"\"\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "text = df['Description'].tolist()\n",
    "token = Tokenizer()\n",
    "token.fit_on_texts(text)\n",
    "vocab = len(token.index_word) + 1\n",
    "encoded_text = token.texts_to_sequences(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = max([len(x) for x in encoded_text])\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['word_counts', 'word_docs', 'filters', 'split', 'lower', 'num_words', 'document_count', 'char_level', 'oov_token', 'index_docs', 'word_index', 'index_word'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'token' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9f43a34858a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtoken_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mword_list1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'index_word'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdrop_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'token' is not defined"
     ]
    }
   ],
   "source": [
    "token_dict = token.__dict__\n",
    "word_list1 = list(token_dict['index_word'].values())\n",
    "drop_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove:\n",
    "- non words (codes, ect)\n",
    "- numbers\n",
    "- stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy\n",
    "nlp = spacy.load('en_vectors_web_lg')\n",
    "def similarityy(x,y):\n",
    "    return(nlp(x).similarity(nlp(y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\olfoa\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "c:\\users\\olfoa\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "c:\\users\\olfoa\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "c:\\users\\olfoa\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "c:\\users\\olfoa\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "c:\\users\\olfoa\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "c:\\users\\olfoa\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "c:\\users\\olfoa\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "c:\\users\\olfoa\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "c:\\users\\olfoa\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "c:\\users\\olfoa\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "c:\\users\\olfoa\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "c:\\users\\olfoa\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "c:\\users\\olfoa\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "c:\\users\\olfoa\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "c:\\users\\olfoa\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "c:\\users\\olfoa\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "c:\\users\\olfoa\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "c:\\users\\olfoa\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "c:\\users\\olfoa\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "c:\\users\\olfoa\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "c:\\users\\olfoa\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "c:\\users\\olfoa\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "c:\\users\\olfoa\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "c:\\users\\olfoa\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "c:\\users\\olfoa\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(word_list1)):\n",
    "    try:\n",
    "        if similarityy(word_list1[i], 'vehicle') < 0.1:\n",
    "            word_list1.pop(i)\n",
    "    except:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "word_list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['inspection',\n",
       " 'after',\n",
       " 'repairs',\n",
       " 'spv',\n",
       " 'insp',\n",
       " 'month',\n",
       " 'ref',\n",
       " 'refueller',\n",
       " '12',\n",
       " 's',\n",
       " 'c',\n",
       " 'gse',\n",
       " 'truck',\n",
       " '5',\n",
       " 'yr',\n",
       " 'cycle',\n",
       " 'a',\n",
       " 'aircraft',\n",
       " 'n',\n",
       " 'rep',\n",
       " 'repair',\n",
       " 'refuelling',\n",
       " 'trk',\n",
       " 'light',\n",
       " 'on',\n",
       " 'replace',\n",
       " 'in',\n",
       " 'leak',\n",
       " 'tank',\n",
       " 'side',\n",
       " 'firehall',\n",
       " 'not',\n",
       " 'start',\n",
       " 'm',\n",
       " 'close',\n",
       " 'quarterly',\n",
       " 'fuel',\n",
       " 'repl',\n",
       " 'year',\n",
       " 'no',\n",
       " 'f',\n",
       " '13750',\n",
       " 'sweeper',\n",
       " 'air',\n",
       " 'dump',\n",
       " 'emo',\n",
       " '13749',\n",
       " '13752',\n",
       " 'mtd',\n",
       " 'hose',\n",
       " '13751',\n",
       " '93685',\n",
       " 'leaking',\n",
       " 'fire',\n",
       " 'hall',\n",
       " 'refueling',\n",
       " '3',\n",
       " 'pressure',\n",
       " '93688',\n",
       " '2',\n",
       " 'proximity',\n",
       " '13748',\n",
       " 'cutting',\n",
       " '13747',\n",
       " 'ns',\n",
       " 'rear',\n",
       " 'teme',\n",
       " 'pump',\n",
       " 'blower',\n",
       " 'engine',\n",
       " 'control',\n",
       " 'out',\n",
       " '04143',\n",
       " '1',\n",
       " 'check',\n",
       " '65298',\n",
       " 'b620',\n",
       " 'will',\n",
       " 'rotary',\n",
       " 'wh',\n",
       " 'tow',\n",
       " 'issue',\n",
       " 'anti',\n",
       " 'diag',\n",
       " '01241',\n",
       " 'except',\n",
       " 'towed',\n",
       " 'tractor',\n",
       " 'low',\n",
       " 'for',\n",
       " 'regen',\n",
       " 'undercoating',\n",
       " 'broken',\n",
       " 'requires',\n",
       " 'plow',\n",
       " 'd',\n",
       " 'filters',\n",
       " 'prox',\n",
       " '93686',\n",
       " 'snow',\n",
       " 'snowplw',\n",
       " 'edges',\n",
       " 'annual',\n",
       " 'meter',\n",
       " 'assist',\n",
       " 'wheel',\n",
       " 'estimate',\n",
       " 'vehicle',\n",
       " '04145',\n",
       " 'change',\n",
       " 'of',\n",
       " 'front',\n",
       " 'valve',\n",
       " '13531',\n",
       " 'issues',\n",
       " 'cable',\n",
       " '65249',\n",
       " '46110',\n",
       " 'batteries',\n",
       " 'off',\n",
       " '13061',\n",
       " 'required',\n",
       " 'crash',\n",
       " 'corrosion',\n",
       " '14214',\n",
       " '82934',\n",
       " 'switch',\n",
       " 'filter',\n",
       " 'pgm',\n",
       " 'high',\n",
       " 'checks',\n",
       " 'caster',\n",
       " 'working',\n",
       " '14',\n",
       " 'is',\n",
       " 'chain',\n",
       " 'auto',\n",
       " 'flow',\n",
       " '81323',\n",
       " '65250',\n",
       " '65703',\n",
       " \"won't\",\n",
       " 'pass',\n",
       " '13060',\n",
       " 'power',\n",
       " '6',\n",
       " '00555',\n",
       " '65254',\n",
       " '82924',\n",
       " 'cancelled',\n",
       " 'ground',\n",
       " 'turret',\n",
       " 'eng',\n",
       " 'door',\n",
       " 'calibration',\n",
       " '69636',\n",
       " '65702',\n",
       " '82914',\n",
       " 'box',\n",
       " 'system',\n",
       " 'from',\n",
       " 'to',\n",
       " 'r',\n",
       " 'steering',\n",
       " 'mod',\n",
       " 'dead',\n",
       " 'ce',\n",
       " 'missing',\n",
       " 'right',\n",
       " 'nozzle',\n",
       " 'and',\n",
       " 'installation',\n",
       " 'shutdown',\n",
       " 'device',\n",
       " 'coslescor',\n",
       " 'grounding',\n",
       " '01241aircraft',\n",
       " 'petro',\n",
       " 'services',\n",
       " '78582',\n",
       " 'defects',\n",
       " 'bumper',\n",
       " 'dvr',\n",
       " 'damage',\n",
       " 'pipe',\n",
       " 'inspect',\n",
       " 'diagnose',\n",
       " '72967',\n",
       " 'broom',\n",
       " '65251',\n",
       " '78612',\n",
       " '78613',\n",
       " '64961',\n",
       " '82921',\n",
       " '82922',\n",
       " '48659',\n",
       " 'tire',\n",
       " 'brake',\n",
       " 'work',\n",
       " 'order',\n",
       " 'test',\n",
       " 'bent',\n",
       " 'sensor',\n",
       " 'rust',\n",
       " 'shut',\n",
       " 'seal',\n",
       " 'de',\n",
       " 'pod',\n",
       " 'case',\n",
       " 'tr',\n",
       " '78596',\n",
       " 'edge',\n",
       " 'exhaust',\n",
       " 'oil',\n",
       " 'lights',\n",
       " '17989',\n",
       " 'radio',\n",
       " 'line',\n",
       " 'duplicate',\n",
       " '22964',\n",
       " 'water',\n",
       " 'wing',\n",
       " 'timeout',\n",
       " 'parameters',\n",
       " 'fender',\n",
       " 'stop',\n",
       " 'key',\n",
       " '2017',\n",
       " 'hydraulic',\n",
       " '70298',\n",
       " 'drive',\n",
       " '65253',\n",
       " 'battery',\n",
       " 'computer',\n",
       " 'needs',\n",
       " 'noise',\n",
       " 'cover',\n",
       " 'install',\n",
       " 'brakes',\n",
       " 'weld',\n",
       " 'transmission',\n",
       " 'head',\n",
       " 'window',\n",
       " 'cracked',\n",
       " 'screen',\n",
       " 'corrison',\n",
       " 'viper',\n",
       " '100',\n",
       " 'headlight',\n",
       " '5th',\n",
       " '64956',\n",
       " 'veh',\n",
       " 'left',\n",
       " 'equipment',\n",
       " 'pto',\n",
       " 'boost',\n",
       " 'need',\n",
       " '23323',\n",
       " 'reel',\n",
       " 'burnt',\n",
       " 'intermittent',\n",
       " 'roof',\n",
       " 'gear',\n",
       " 'e',\n",
       " 'safety',\n",
       " 'icer',\n",
       " 'burner',\n",
       " 'electrical',\n",
       " 'shaft',\n",
       " 'cylinder',\n",
       " 'broke',\n",
       " 'corrision',\n",
       " '64558',\n",
       " 'back',\n",
       " 'up',\n",
       " 'blade',\n",
       " 'wiper',\n",
       " '22963',\n",
       " 'cab',\n",
       " 'minor',\n",
       " 'rrr',\n",
       " 'mirror',\n",
       " 'red',\n",
       " 'tires',\n",
       " 'top',\n",
       " 'windshield',\n",
       " 'lock',\n",
       " 'coolant',\n",
       " 'coalescor',\n",
       " 'certification',\n",
       " 'tremcar',\n",
       " 'malfunction',\n",
       " 'printer',\n",
       " 'force',\n",
       " 'axle',\n",
       " 'debris',\n",
       " 'years',\n",
       " 'ignition',\n",
       " 'running',\n",
       " 'ice',\n",
       " 'cracks',\n",
       " '78594',\n",
       " '82923',\n",
       " 'starting',\n",
       " '2x',\n",
       " '64556',\n",
       " 'engage',\n",
       " 'load',\n",
       " 'beacon',\n",
       " 'l',\n",
       " 'hand',\n",
       " 'multiple',\n",
       " 'loose',\n",
       " 'fleet',\n",
       " 'eject',\n",
       " 'major',\n",
       " 'wont',\n",
       " 'trans',\n",
       " 'bar',\n",
       " 'alarm',\n",
       " 'driver',\n",
       " 'rpm',\n",
       " 'u',\n",
       " 'drv',\n",
       " 'hard',\n",
       " 'cfue',\n",
       " 'at',\n",
       " 'throttle',\n",
       " 'hub',\n",
       " '4',\n",
       " 'b',\n",
       " '620',\n",
       " 'code',\n",
       " 'pas',\n",
       " 'chassis',\n",
       " 'techs',\n",
       " 'parts',\n",
       " 'welding',\n",
       " 'down',\n",
       " 'bank',\n",
       " 'sblow',\n",
       " 'splow',\n",
       " 'frame',\n",
       " 'charge',\n",
       " 'reverse',\n",
       " 'remove',\n",
       " 'panel',\n",
       " 'cfr',\n",
       " 'see',\n",
       " 'boards',\n",
       " 'etc',\n",
       " 'bolts',\n",
       " 'warranty',\n",
       " 'ladder',\n",
       " 'wce',\n",
       " 'drain',\n",
       " 'foam',\n",
       " \"dvr's\",\n",
       " 'bolt',\n",
       " 'generator',\n",
       " 'stuck',\n",
       " 'gauge',\n",
       " 'boom',\n",
       " 'pumping',\n",
       " 'rt',\n",
       " '11',\n",
       " 'pre',\n",
       " 'the',\n",
       " 'adjustment',\n",
       " 'fuse',\n",
       " 'tubes',\n",
       " 'forced',\n",
       " 'wash',\n",
       " 'as',\n",
       " 'per',\n",
       " 'aux',\n",
       " 'heater',\n",
       " 'tech',\n",
       " 'certifications',\n",
       " 'welds',\n",
       " 'assembly',\n",
       " 'blades',\n",
       " 'recover',\n",
       " 'lower',\n",
       " 'dash',\n",
       " 'holding',\n",
       " 'ann',\n",
       " 'engaging',\n",
       " '64559',\n",
       " 'seat',\n",
       " 'turbo',\n",
       " 'new',\n",
       " 'motor',\n",
       " '81370',\n",
       " 'tower',\n",
       " 'application',\n",
       " 'are',\n",
       " 'shoe',\n",
       " 'pax',\n",
       " 'shafts',\n",
       " 'fluid',\n",
       " 'into',\n",
       " 'warning',\n",
       " 'eco',\n",
       " 'logic',\n",
       " 'compartment',\n",
       " 'camera',\n",
       " 'abs',\n",
       " '7',\n",
       " 'beam',\n",
       " 'marker',\n",
       " 'bracket',\n",
       " 'x2',\n",
       " 'comp',\n",
       " 'passenger',\n",
       " 'monitors',\n",
       " 'press',\n",
       " 'driwrite',\n",
       " 'be',\n",
       " 'monitor',\n",
       " 'plug',\n",
       " 'emergency',\n",
       " 'horn',\n",
       " 'washer',\n",
       " 'adjust',\n",
       " 'forces',\n",
       " 'conduct',\n",
       " 'grinding',\n",
       " 'spare',\n",
       " 'too',\n",
       " 'fan',\n",
       " 'recovery',\n",
       " 'fss',\n",
       " 'technicians',\n",
       " 'main',\n",
       " 'joint',\n",
       " 'wheels',\n",
       " 'error',\n",
       " 'heavy',\n",
       " 'muffler',\n",
       " 'overheating',\n",
       " 'shoes',\n",
       " 'assy',\n",
       " 'castors',\n",
       " 'harness',\n",
       " '16',\n",
       " 'shift',\n",
       " 'spreader',\n",
       " 'grill',\n",
       " 'salt',\n",
       " 'blown',\n",
       " 'belt',\n",
       " '67948',\n",
       " 'trap',\n",
       " 'odometer',\n",
       " 'x',\n",
       " 'steps',\n",
       " 'painting',\n",
       " 'wooden',\n",
       " 'park',\n",
       " 'seized',\n",
       " 'spring',\n",
       " 'requesting',\n",
       " 'track',\n",
       " 'very',\n",
       " '25043',\n",
       " '25044',\n",
       " '25045',\n",
       " 'booster',\n",
       " 'inlet',\n",
       " \"req'd\",\n",
       " 'turning',\n",
       " 'when',\n",
       " 'activated',\n",
       " 'charging',\n",
       " 'l3',\n",
       " 'flir',\n",
       " 'fog',\n",
       " 'properly',\n",
       " 'nitrogen',\n",
       " '2nd',\n",
       " '9',\n",
       " 'red9',\n",
       " 'gasket',\n",
       " 'button',\n",
       " 'verification',\n",
       " 'leaks',\n",
       " 'wipers',\n",
       " 'replacing',\n",
       " 'set',\n",
       " 'latch',\n",
       " 'pad',\n",
       " 'vessel',\n",
       " 'counter',\n",
       " 'reading',\n",
       " 'move',\n",
       " 'electronic',\n",
       " 'clamp',\n",
       " 'diff',\n",
       " 'problems',\n",
       " 'nil',\n",
       " 'scully',\n",
       " 'waiver',\n",
       " 'citerne',\n",
       " 'desiccant',\n",
       " 'response',\n",
       " 'notes',\n",
       " 'housing',\n",
       " 'product',\n",
       " 'lever',\n",
       " 'cut',\n",
       " 'failed',\n",
       " 'goose',\n",
       " 'neck',\n",
       " 'blue',\n",
       " 'deadman',\n",
       " 'hp',\n",
       " \"req's\",\n",
       " 'seals',\n",
       " 'turn',\n",
       " 'bottom',\n",
       " 'arm',\n",
       " 'recirculation',\n",
       " 'dent',\n",
       " 'falling',\n",
       " 'coupler',\n",
       " 'worn',\n",
       " 'wire',\n",
       " 'with',\n",
       " 'emission',\n",
       " 'hatch',\n",
       " 'require',\n",
       " \"driver's\",\n",
       " 'dmg',\n",
       " 'curb',\n",
       " 'headlights',\n",
       " 'handle',\n",
       " 'man',\n",
       " 'master',\n",
       " 'or',\n",
       " 'intel',\n",
       " 'cap',\n",
       " 'pin',\n",
       " 'jbt',\n",
       " 'primary',\n",
       " 'swivel',\n",
       " 'bucket',\n",
       " 'fault',\n",
       " 'landing',\n",
       " 'calibrate',\n",
       " 'reset',\n",
       " 'octaflo',\n",
       " 're',\n",
       " 'gauges',\n",
       " 'pads',\n",
       " 'hot',\n",
       " 'contracted',\n",
       " 'end',\n",
       " 'split',\n",
       " 'vech',\n",
       " 'semi',\n",
       " 'outrigger',\n",
       " 'flex',\n",
       " 'type',\n",
       " 'beeper',\n",
       " 'shute',\n",
       " 'bearing',\n",
       " 'defect',\n",
       " 'alternator',\n",
       " 'stay',\n",
       " 'driveshaft',\n",
       " 'over',\n",
       " 'yoke',\n",
       " 'gash',\n",
       " 'svc',\n",
       " 'idle',\n",
       " 'shutting',\n",
       " 'snapped',\n",
       " 'castor',\n",
       " 'bad',\n",
       " 'excessive',\n",
       " 'chute',\n",
       " 'slash',\n",
       " 'angle',\n",
       " 'hyd',\n",
       " 'lift',\n",
       " 'breakdown',\n",
       " 'cylinders',\n",
       " 'steer',\n",
       " 'crack',\n",
       " 'hgr',\n",
       " 'way',\n",
       " 'faulty',\n",
       " 'injection',\n",
       " 'airbrakes',\n",
       " 'protctor',\n",
       " 'dog',\n",
       " 'plastic',\n",
       " 'epoke',\n",
       " 'tread',\n",
       " 'tailgate',\n",
       " 'locks',\n",
       " \"don't\",\n",
       " 'unlock',\n",
       " 'barcket',\n",
       " 'tarp',\n",
       " 'dryer',\n",
       " 'supply',\n",
       " 'non',\n",
       " 'functional',\n",
       " 'he',\n",
       " 'strap',\n",
       " '143',\n",
       " 'ces',\n",
       " 'while',\n",
       " 'braking',\n",
       " 'market',\n",
       " 'requests',\n",
       " 'cef',\n",
       " 'bridgewater',\n",
       " 'trl',\n",
       " 'socket',\n",
       " 'cables',\n",
       " 'equip',\n",
       " 'below',\n",
       " 'controls',\n",
       " 'sander',\n",
       " 'glad',\n",
       " 'mud',\n",
       " 'flap',\n",
       " 'king',\n",
       " 'pins',\n",
       " 'came',\n",
       " 'sand',\n",
       " 'sheared',\n",
       " 'spinner',\n",
       " 'board',\n",
       " 'black',\n",
       " 'ripped',\n",
       " '25202',\n",
       " 'pipes',\n",
       " 'quarts',\n",
       " 'valves',\n",
       " 'constantly',\n",
       " 'dome',\n",
       " 'trkf',\n",
       " 'cra',\n",
       " 'quartz',\n",
       " 'display',\n",
       " 'arffv',\n",
       " 'operating',\n",
       " 'operations',\n",
       " 'guard',\n",
       " 'nitro',\n",
       " 'stow',\n",
       " 'note',\n",
       " 'burned',\n",
       " 'chafing',\n",
       " 'driverside',\n",
       " 'bottle',\n",
       " 'joystick',\n",
       " 'ajar',\n",
       " 'alarn',\n",
       " 'goiong',\n",
       " 'r1',\n",
       " 'ac',\n",
       " 'centre',\n",
       " 'sticks',\n",
       " 'incr',\n",
       " 'hurst',\n",
       " 'charger',\n",
       " 'singnal',\n",
       " 'ivo',\n",
       " 'extinguisher',\n",
       " 'wires',\n",
       " 'hanging',\n",
       " 'chargers',\n",
       " 'taillight',\n",
       " 'parking',\n",
       " 'partially',\n",
       " 'br',\n",
       " 'center',\n",
       " 'replacin',\n",
       " 'exhuast',\n",
       " 'flange',\n",
       " 'signal',\n",
       " 'gets',\n",
       " 'truc',\n",
       " 'outside',\n",
       " 'middle',\n",
       " 'around',\n",
       " 'fitting',\n",
       " 'went',\n",
       " 'maint',\n",
       " 'mo',\n",
       " 'leeking',\n",
       " 'separator',\n",
       " 'full',\n",
       " 'self',\n",
       " 'lowering',\n",
       " 'wigwag',\n",
       " 'operated',\n",
       " 'touret',\n",
       " 'rh',\n",
       " 'flasher',\n",
       " 'wabasto',\n",
       " 'receptical',\n",
       " 'all',\n",
       " 'fluids',\n",
       " 'scene',\n",
       " 'tip',\n",
       " 'fes',\n",
       " 'changed',\n",
       " 'dvrs',\n",
       " '2005',\n",
       " 'recirc',\n",
       " 'replacement',\n",
       " 'replaced',\n",
       " 'visual',\n",
       " 'inac',\n",
       " 'finch',\n",
       " 'level',\n",
       " 'speedomiter',\n",
       " 'connection',\n",
       " 'collant',\n",
       " 'refuellng',\n",
       " 'accelerate',\n",
       " 'quotes',\n",
       " 'cannot',\n",
       " 'release',\n",
       " 'injector',\n",
       " 'frfont',\n",
       " 'severely',\n",
       " 'almost',\n",
       " 'expire',\n",
       " 'overfill',\n",
       " 'diagnostics',\n",
       " 'slice',\n",
       " 'holder',\n",
       " 'nail',\n",
       " 'pres',\n",
       " 'print',\n",
       " 'during',\n",
       " 'porximity',\n",
       " 'afer',\n",
       " 'ou',\n",
       " 'disintegrated',\n",
       " 'vor',\n",
       " 'ball',\n",
       " 'api',\n",
       " 'commercial',\n",
       " 'gate',\n",
       " 'apart',\n",
       " 'drivers',\n",
       " 'connector',\n",
       " 'needed',\n",
       " 'wind',\n",
       " 'grd',\n",
       " 'tight',\n",
       " 'hi',\n",
       " 'rigid',\n",
       " 'temp',\n",
       " 'probe',\n",
       " 'hole',\n",
       " 'arms',\n",
       " 'short',\n",
       " 'incorrect',\n",
       " 'inside',\n",
       " 'handrail',\n",
       " 'controller',\n",
       " 'nipple',\n",
       " 'by',\n",
       " 'engin',\n",
       " 'spike',\n",
       " 'deffects',\n",
       " 'loading',\n",
       " 'coupling',\n",
       " 'spool',\n",
       " 'plus',\n",
       " 'additive',\n",
       " 'green',\n",
       " 'cluch',\n",
       " 'printing',\n",
       " 'ai',\n",
       " 'malfunctioning',\n",
       " 'tilt',\n",
       " 'sys',\n",
       " 'tension',\n",
       " 'intermediate',\n",
       " 'reluctant',\n",
       " 'batt',\n",
       " 'tem',\n",
       " 'warrenty',\n",
       " 'sump',\n",
       " 'est',\n",
       " 'voltage',\n",
       " 'malfuntioning',\n",
       " 'yellow',\n",
       " 'dic',\n",
       " 'emissions',\n",
       " 'chipped',\n",
       " 'delivery',\n",
       " 'c13751',\n",
       " 'lgt',\n",
       " 'dim',\n",
       " '13751repairs',\n",
       " 'underwing',\n",
       " 'hea',\n",
       " 'outlet',\n",
       " 'continue',\n",
       " 'fuelling',\n",
       " 'def',\n",
       " 'airhose',\n",
       " 'defuel',\n",
       " 'plumbing',\n",
       " 'go',\n",
       " 'getting',\n",
       " 'weak',\n",
       " 'stops',\n",
       " 'warnig',\n",
       " 'rail',\n",
       " 'sticking',\n",
       " 'ctr',\n",
       " 'intake',\n",
       " 'perform',\n",
       " \"gov't\",\n",
       " 'contract',\n",
       " 'first',\n",
       " 'technician',\n",
       " 'maintenance',\n",
       " 'burners',\n",
       " 'lockout',\n",
       " 'request',\n",
       " 'turbine',\n",
       " 'electrica',\n",
       " 'breaker',\n",
       " 'swit',\n",
       " 'spray',\n",
       " 'nozzel',\n",
       " 'actuator',\n",
       " 'shutoff',\n",
       " 'assisting',\n",
       " 'ndt',\n",
       " 'report',\n",
       " \"con't\",\n",
       " 'secure',\n",
       " 'program',\n",
       " 'gal',\n",
       " \"lt's\",\n",
       " 'expulsion',\n",
       " 'si',\n",
       " 'elect',\n",
       " 'hoses',\n",
       " 'handles',\n",
       " 'tender',\n",
       " 'requested',\n",
       " 'premier',\n",
       " 'clamps',\n",
       " 'cert',\n",
       " 'modificati',\n",
       " 'modification',\n",
       " 'goulds',\n",
       " 'procharger',\n",
       " 'pumps',\n",
       " 'ex',\n",
       " 'flush',\n",
       " 'lines',\n",
       " 'wrong',\n",
       " 'undercarriage',\n",
       " 'foreign',\n",
       " 'object',\n",
       " 'core',\n",
       " 'adjustor',\n",
       " 'coned',\n",
       " 'rubbing',\n",
       " 'fra',\n",
       " 'wafers',\n",
       " 'differential',\n",
       " 'requireds',\n",
       " 'combust',\n",
       " 'failure',\n",
       " 'pattern',\n",
       " 'jack',\n",
       " 'x1',\n",
       " 'codes',\n",
       " 'direction',\n",
       " 'postion',\n",
       " 'needes',\n",
       " 'starter',\n",
       " 'repai',\n",
       " 'problem',\n",
       " 'lug',\n",
       " 'nuts',\n",
       " 'hydralic',\n",
       " 'bristle',\n",
       " 'spacers',\n",
       " 'mat',\n",
       " 'an',\n",
       " '51',\n",
       " '250',\n",
       " 'misc',\n",
       " 'frost',\n",
       " 'chainns',\n",
       " 'bearings',\n",
       " 'collision',\n",
       " 'flat',\n",
       " 'breather',\n",
       " 'cant',\n",
       " 'keeps',\n",
       " 'tee',\n",
       " 'place',\n",
       " 'sending',\n",
       " 'unit',\n",
       " 'rams',\n",
       " 'transfer',\n",
       " 'auger',\n",
       " '22',\n",
       " 'step',\n",
       " '78852',\n",
       " 'sidewall',\n",
       " 'rims',\n",
       " 'freeze',\n",
       " 'accelerator',\n",
       " 'has',\n",
       " 'shor',\n",
       " 'lhs',\n",
       " 'seeping',\n",
       " 'joints',\n",
       " 'connected',\n",
       " 'guage',\n",
       " 'cone',\n",
       " 'impeller',\n",
       " 'buzzer',\n",
       " 'req',\n",
       " 'inspec',\n",
       " 'lighting',\n",
       " 'vib',\n",
       " 'shake',\n",
       " 'going',\n",
       " 'cb',\n",
       " 'milky',\n",
       " 'look',\n",
       " \"hydraulic's\",\n",
       " 'reaplace',\n",
       " \"doesn't\",\n",
       " 'ride',\n",
       " 'heating',\n",
       " 'shock',\n",
       " 'absorber',\n",
       " 'fam',\n",
       " 'fell',\n",
       " 'o',\n",
       " 'rhs',\n",
       " 'sheare',\n",
       " 'attached',\n",
       " 'small',\n",
       " 'manufacture',\n",
       " 'stabilizer',\n",
       " 'push',\n",
       " 'mount',\n",
       " 'pulley',\n",
       " 'reinforced',\n",
       " 'bagotville',\n",
       " 'suspension',\n",
       " 'spot',\n",
       " 'wall',\n",
       " 'attachment',\n",
       " 'output',\n",
       " 'rad',\n",
       " 'plate',\n",
       " 'link',\n",
       " 'axl',\n",
       " 'impact',\n",
       " 'blinking',\n",
       " 'cooling',\n",
       " 'egde',\n",
       " '8tractor',\n",
       " 'hour',\n",
       " 'pintle',\n",
       " 'hook',\n",
       " 'opened',\n",
       " 'd14',\n",
       " '413',\n",
       " 'sqn',\n",
       " 'selector',\n",
       " 'val',\n",
       " '405',\n",
       " 'incident',\n",
       " 'stock',\n",
       " 'sticky',\n",
       " 'inspections',\n",
       " '405sqn',\n",
       " 'hood',\n",
       " 'shocks',\n",
       " 'tranny',\n",
       " 'shifter',\n",
       " 'nsn',\n",
       " '14mss',\n",
       " 'aro',\n",
       " '10',\n",
       " ...]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Tokenizer in module keras_preprocessing.text object:\n",
      "\n",
      "class Tokenizer(builtins.object)\n",
      " |  Text tokenization utility class.\n",
      " |  \n",
      " |  This class allows to vectorize a text corpus, by turning each\n",
      " |  text into either a sequence of integers (each integer being the index\n",
      " |  of a token in a dictionary) or into a vector where the coefficient\n",
      " |  for each token could be binary, based on word count, based on tf-idf...\n",
      " |  \n",
      " |  # Arguments\n",
      " |      num_words: the maximum number of words to keep, based\n",
      " |          on word frequency. Only the most common `num_words-1` words will\n",
      " |          be kept.\n",
      " |      filters: a string where each element is a character that will be\n",
      " |          filtered from the texts. The default is all punctuation, plus\n",
      " |          tabs and line breaks, minus the `'` character.\n",
      " |      lower: boolean. Whether to convert the texts to lowercase.\n",
      " |      split: str. Separator for word splitting.\n",
      " |      char_level: if True, every character will be treated as a token.\n",
      " |      oov_token: if given, it will be added to word_index and used to\n",
      " |          replace out-of-vocabulary words during text_to_sequence calls\n",
      " |  \n",
      " |  By default, all punctuation is removed, turning the texts into\n",
      " |  space-separated sequences of words\n",
      " |  (words maybe include the `'` character). These sequences are then\n",
      " |  split into lists of tokens. They will then be indexed or vectorized.\n",
      " |  \n",
      " |  `0` is a reserved index that won't be assigned to any word.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ', char_level=False, oov_token=None, document_count=0, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit_on_sequences(self, sequences)\n",
      " |      Updates internal vocabulary based on a list of sequences.\n",
      " |      \n",
      " |      Required before using `sequences_to_matrix`\n",
      " |      (if `fit_on_texts` was never called).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          sequences: A list of sequence.\n",
      " |              A \"sequence\" is a list of integer word indices.\n",
      " |  \n",
      " |  fit_on_texts(self, texts)\n",
      " |      Updates internal vocabulary based on a list of texts.\n",
      " |      \n",
      " |      In the case where texts contains lists,\n",
      " |      we assume each entry of the lists to be a token.\n",
      " |      \n",
      " |      Required before using `texts_to_sequences` or `texts_to_matrix`.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          texts: can be a list of strings,\n",
      " |              a generator of strings (for memory-efficiency),\n",
      " |              or a list of list of strings.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the tokenizer configuration as Python dictionary.\n",
      " |      The word count dictionaries used by the tokenizer get serialized\n",
      " |      into plain JSON, so that the configuration can be read by other\n",
      " |      projects.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A Python dictionary with the tokenizer configuration.\n",
      " |  \n",
      " |  sequences_to_matrix(self, sequences, mode='binary')\n",
      " |      Converts a list of sequences into a Numpy matrix.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          sequences: list of sequences\n",
      " |              (a sequence is a list of integer word indices).\n",
      " |          mode: one of \"binary\", \"count\", \"tfidf\", \"freq\"\n",
      " |      \n",
      " |      # Returns\n",
      " |          A Numpy matrix.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: In case of invalid `mode` argument,\n",
      " |              or if the Tokenizer requires to be fit to sample data.\n",
      " |  \n",
      " |  sequences_to_texts(self, sequences)\n",
      " |      Transforms each sequence into a list of text.\n",
      " |      \n",
      " |      Only top `num_words-1` most frequent words will be taken into account.\n",
      " |      Only words known by the tokenizer will be taken into account.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          sequences: A list of sequences (list of integers).\n",
      " |      \n",
      " |      # Returns\n",
      " |          A list of texts (strings)\n",
      " |  \n",
      " |  sequences_to_texts_generator(self, sequences)\n",
      " |      Transforms each sequence in `sequences` to a list of texts(strings).\n",
      " |      \n",
      " |      Each sequence has to a list of integers.\n",
      " |      In other words, sequences should be a list of sequences\n",
      " |      \n",
      " |      Only top `num_words-1` most frequent words will be taken into account.\n",
      " |      Only words known by the tokenizer will be taken into account.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          sequences: A list of sequences.\n",
      " |      \n",
      " |      # Yields\n",
      " |          Yields individual texts.\n",
      " |  \n",
      " |  texts_to_matrix(self, texts, mode='binary')\n",
      " |      Convert a list of texts to a Numpy matrix.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          texts: list of strings.\n",
      " |          mode: one of \"binary\", \"count\", \"tfidf\", \"freq\".\n",
      " |      \n",
      " |      # Returns\n",
      " |          A Numpy matrix.\n",
      " |  \n",
      " |  texts_to_sequences(self, texts)\n",
      " |      Transforms each text in texts to a sequence of integers.\n",
      " |      \n",
      " |      Only top `num_words-1` most frequent words will be taken into account.\n",
      " |      Only words known by the tokenizer will be taken into account.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          texts: A list of texts (strings).\n",
      " |      \n",
      " |      # Returns\n",
      " |          A list of sequences.\n",
      " |  \n",
      " |  texts_to_sequences_generator(self, texts)\n",
      " |      Transforms each text in `texts` to a sequence of integers.\n",
      " |      \n",
      " |      Each item in texts can also be a list,\n",
      " |      in which case we assume each item of that list to be a token.\n",
      " |      \n",
      " |      Only top `num_words-1` most frequent words will be taken into account.\n",
      " |      Only words known by the tokenizer will be taken into account.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          texts: A list of texts (strings).\n",
      " |      \n",
      " |      # Yields\n",
      " |          Yields individual sequences.\n",
      " |  \n",
      " |  to_json(self, **kwargs)\n",
      " |      Returns a JSON string containing the tokenizer configuration.\n",
      " |      To load a tokenizer from a JSON string, use\n",
      " |      `keras.preprocessing.text.tokenizer_from_json(json_string)`.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          **kwargs: Additional keyword arguments\n",
      " |              to be passed to `json.dumps()`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A JSON string containing the tokenizer configuration.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(help(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create ranges of days WIP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
