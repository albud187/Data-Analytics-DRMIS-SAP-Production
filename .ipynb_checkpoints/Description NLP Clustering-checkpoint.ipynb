{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "import spacy\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv1D, MaxPool1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"../Data-Analytics-DRMIS-SAP-Production-DATA/\"\n",
    "\n",
    "df = pd.read_csv(data_folder + 'vehicle_df_interest.csv', index_col = 0).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order</th>\n",
       "      <th>Description</th>\n",
       "      <th>Total planned costs</th>\n",
       "      <th>PM Orders planned hours</th>\n",
       "      <th>Technical Status</th>\n",
       "      <th>PM Orders actual hours</th>\n",
       "      <th>Tail Number / Identifier</th>\n",
       "      <th>User Status</th>\n",
       "      <th>Equipment</th>\n",
       "      <th>MaintActivityType</th>\n",
       "      <th>Main work center</th>\n",
       "      <th>Vehicle Type</th>\n",
       "      <th>Utilizer</th>\n",
       "      <th>Actual release date</th>\n",
       "      <th>Basic finish date</th>\n",
       "      <th>days WIP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1102281442</td>\n",
       "      <td>48659 - Repair starting issue</td>\n",
       "      <td>8,467.22</td>\n",
       "      <td>79.0</td>\n",
       "      <td>SERV</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2002-48659</td>\n",
       "      <td>OAPP</td>\n",
       "      <td>20110316</td>\n",
       "      <td>L01</td>\n",
       "      <td>AG-LS-V2</td>\n",
       "      <td>EV0B22</td>\n",
       "      <td>102</td>\n",
       "      <td>15/05/2018</td>\n",
       "      <td>09/07/2018</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1102375576</td>\n",
       "      <td>48659 - 2x Defects</td>\n",
       "      <td>321.54</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SERV</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2002-48659</td>\n",
       "      <td>OAPP</td>\n",
       "      <td>20110316</td>\n",
       "      <td>L01</td>\n",
       "      <td>AG-LS-V2</td>\n",
       "      <td>EV0B22</td>\n",
       "      <td>102</td>\n",
       "      <td>11/12/2018</td>\n",
       "      <td>11/12/2018</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1102134109</td>\n",
       "      <td>Repairs After Inspection</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SERV</td>\n",
       "      <td>33.5</td>\n",
       "      <td>2002-48659</td>\n",
       "      <td>OAPP</td>\n",
       "      <td>20110316</td>\n",
       "      <td>L01</td>\n",
       "      <td>AG-LS-V2</td>\n",
       "      <td>EV0B22</td>\n",
       "      <td>102</td>\n",
       "      <td>24/07/2017</td>\n",
       "      <td>12/10/2017</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1102493393</td>\n",
       "      <td>TRUCK DUMP S/C INSP-12 MONTH</td>\n",
       "      <td>1,315.80</td>\n",
       "      <td>12.0</td>\n",
       "      <td>SERV</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2002-48659</td>\n",
       "      <td>OAPP</td>\n",
       "      <td>20110316</td>\n",
       "      <td>L27</td>\n",
       "      <td>AG-LS-V2</td>\n",
       "      <td>EV0B22</td>\n",
       "      <td>102</td>\n",
       "      <td>13/09/2019</td>\n",
       "      <td>21/10/2019</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1102498902</td>\n",
       "      <td>48659 Repairs after inspection</td>\n",
       "      <td>8,333.40</td>\n",
       "      <td>76.0</td>\n",
       "      <td>SERV</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2002-48659</td>\n",
       "      <td>OAPP</td>\n",
       "      <td>20110316</td>\n",
       "      <td>L01</td>\n",
       "      <td>AG-LS-V2</td>\n",
       "      <td>EV0B22</td>\n",
       "      <td>102</td>\n",
       "      <td>24/09/2019</td>\n",
       "      <td>06/02/2020</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2103</td>\n",
       "      <td>1101971411</td>\n",
       "      <td>GSE - Repairs After Inspection</td>\n",
       "      <td>644.86</td>\n",
       "      <td>4.0</td>\n",
       "      <td>SERV</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1988-82934</td>\n",
       "      <td>OAPP</td>\n",
       "      <td>20111634</td>\n",
       "      <td>L01</td>\n",
       "      <td>AG-LH-V2</td>\n",
       "      <td>EV0E76</td>\n",
       "      <td>102</td>\n",
       "      <td>17/08/2016</td>\n",
       "      <td>17/08/2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2104</td>\n",
       "      <td>1101967472</td>\n",
       "      <td>GSE- Quarterly Inspection</td>\n",
       "      <td>313.71</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SERV</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1988-82934</td>\n",
       "      <td>OAPP</td>\n",
       "      <td>20111634</td>\n",
       "      <td>L27</td>\n",
       "      <td>AG-LH-V2</td>\n",
       "      <td>EV0E76</td>\n",
       "      <td>102</td>\n",
       "      <td>09/08/2016</td>\n",
       "      <td>17/08/2016</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2105</td>\n",
       "      <td>1102041733</td>\n",
       "      <td>GSE - Repair Intermittent Start</td>\n",
       "      <td>245.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>SERV</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1988-82934</td>\n",
       "      <td>OAPP</td>\n",
       "      <td>20111634</td>\n",
       "      <td>L01</td>\n",
       "      <td>AG-LH-V2</td>\n",
       "      <td>EV0E76</td>\n",
       "      <td>102</td>\n",
       "      <td>11/01/2017</td>\n",
       "      <td>13/01/2017</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2106</td>\n",
       "      <td>1102174720</td>\n",
       "      <td>GSE - Quarterly Inspection</td>\n",
       "      <td>313.71</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SERV</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1988-82934</td>\n",
       "      <td>OAPP</td>\n",
       "      <td>20111634</td>\n",
       "      <td>L27</td>\n",
       "      <td>AG-LH-V2</td>\n",
       "      <td>EV0E76</td>\n",
       "      <td>102</td>\n",
       "      <td>02/10/2017</td>\n",
       "      <td>06/10/2017</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2107</td>\n",
       "      <td>1102366817</td>\n",
       "      <td>82934- Repair Transmission Issues.</td>\n",
       "      <td>3,001.04</td>\n",
       "      <td>28.0</td>\n",
       "      <td>SERV</td>\n",
       "      <td>13.5</td>\n",
       "      <td>1988-82934</td>\n",
       "      <td>OAPP</td>\n",
       "      <td>20111634</td>\n",
       "      <td>nil</td>\n",
       "      <td>AG-LH-V2</td>\n",
       "      <td>EV0E76</td>\n",
       "      <td>102</td>\n",
       "      <td>22/11/2018</td>\n",
       "      <td>13/12/2018</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2108 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Order                         Description Total planned costs  \\\n",
       "0     1102281442       48659 - Repair starting issue            8,467.22   \n",
       "1     1102375576                  48659 - 2x Defects              321.54   \n",
       "2     1102134109            Repairs After Inspection                   0   \n",
       "3     1102493393        TRUCK DUMP S/C INSP-12 MONTH            1,315.80   \n",
       "4     1102498902      48659 Repairs after inspection            8,333.40   \n",
       "...          ...                                 ...                 ...   \n",
       "2103  1101971411      GSE - Repairs After Inspection              644.86   \n",
       "2104  1101967472           GSE- Quarterly Inspection              313.71   \n",
       "2105  1102041733     GSE - Repair Intermittent Start               245.9   \n",
       "2106  1102174720          GSE - Quarterly Inspection              313.71   \n",
       "2107  1102366817  82934- Repair Transmission Issues.            3,001.04   \n",
       "\n",
       "      PM Orders planned hours Technical Status  PM Orders actual hours  \\\n",
       "0                        79.0             SERV                    76.0   \n",
       "1                         3.0             SERV                     3.0   \n",
       "2                         0.0             SERV                    33.5   \n",
       "3                        12.0             SERV                    12.0   \n",
       "4                        76.0             SERV                    82.0   \n",
       "...                       ...              ...                     ...   \n",
       "2103                      4.0             SERV                     3.0   \n",
       "2104                      3.0             SERV                     3.0   \n",
       "2105                      2.0             SERV                     2.0   \n",
       "2106                      3.0             SERV                     3.0   \n",
       "2107                     28.0             SERV                    13.5   \n",
       "\n",
       "     Tail Number / Identifier User Status  Equipment MaintActivityType  \\\n",
       "0                  2002-48659        OAPP   20110316               L01   \n",
       "1                  2002-48659        OAPP   20110316               L01   \n",
       "2                  2002-48659        OAPP   20110316               L01   \n",
       "3                  2002-48659        OAPP   20110316               L27   \n",
       "4                  2002-48659        OAPP   20110316               L01   \n",
       "...                       ...         ...        ...               ...   \n",
       "2103               1988-82934        OAPP   20111634               L01   \n",
       "2104               1988-82934        OAPP   20111634               L27   \n",
       "2105               1988-82934        OAPP   20111634               L01   \n",
       "2106               1988-82934        OAPP   20111634               L27   \n",
       "2107               1988-82934        OAPP   20111634               nil   \n",
       "\n",
       "     Main work center Vehicle Type  Utilizer Actual release date  \\\n",
       "0            AG-LS-V2       EV0B22       102          15/05/2018   \n",
       "1            AG-LS-V2       EV0B22       102          11/12/2018   \n",
       "2            AG-LS-V2       EV0B22       102          24/07/2017   \n",
       "3            AG-LS-V2       EV0B22       102          13/09/2019   \n",
       "4            AG-LS-V2       EV0B22       102          24/09/2019   \n",
       "...               ...          ...       ...                 ...   \n",
       "2103         AG-LH-V2       EV0E76       102          17/08/2016   \n",
       "2104         AG-LH-V2       EV0E76       102          09/08/2016   \n",
       "2105         AG-LH-V2       EV0E76       102          11/01/2017   \n",
       "2106         AG-LH-V2       EV0E76       102          02/10/2017   \n",
       "2107         AG-LH-V2       EV0E76       102          22/11/2018   \n",
       "\n",
       "     Basic finish date  days WIP  \n",
       "0           09/07/2018        55  \n",
       "1           11/12/2018         0  \n",
       "2           12/10/2017        80  \n",
       "3           21/10/2019        38  \n",
       "4           06/02/2020       135  \n",
       "...                ...       ...  \n",
       "2103        17/08/2016         0  \n",
       "2104        17/08/2016         8  \n",
       "2105        13/01/2017         2  \n",
       "2106        06/10/2017         4  \n",
       "2107        13/12/2018        21  \n",
       "\n",
       "[2108 rows x 16 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df['Description'].tolist()\n",
    "token = Tokenizer()\n",
    "token.fit_on_texts(text)\n",
    "vocab = len(token.index_word) + 1\n",
    "encoded_text = token.texts_to_sequences(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = max([len(x) for x in encoded_text])\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_dict = token.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['word_counts', 'word_docs', 'filters', 'split', 'lower', 'num_words', 'document_count', 'char_level', 'oov_token', 'index_docs', 'word_index', 'index_word'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list1 = list(token_dict['index_word'].values())\n",
    "drop_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove:\n",
    "- non words (codes, ect)\n",
    "- numbers\n",
    "- stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Tokenizer in module keras_preprocessing.text object:\n",
      "\n",
      "class Tokenizer(builtins.object)\n",
      " |  Text tokenization utility class.\n",
      " |  \n",
      " |  This class allows to vectorize a text corpus, by turning each\n",
      " |  text into either a sequence of integers (each integer being the index\n",
      " |  of a token in a dictionary) or into a vector where the coefficient\n",
      " |  for each token could be binary, based on word count, based on tf-idf...\n",
      " |  \n",
      " |  # Arguments\n",
      " |      num_words: the maximum number of words to keep, based\n",
      " |          on word frequency. Only the most common `num_words-1` words will\n",
      " |          be kept.\n",
      " |      filters: a string where each element is a character that will be\n",
      " |          filtered from the texts. The default is all punctuation, plus\n",
      " |          tabs and line breaks, minus the `'` character.\n",
      " |      lower: boolean. Whether to convert the texts to lowercase.\n",
      " |      split: str. Separator for word splitting.\n",
      " |      char_level: if True, every character will be treated as a token.\n",
      " |      oov_token: if given, it will be added to word_index and used to\n",
      " |          replace out-of-vocabulary words during text_to_sequence calls\n",
      " |  \n",
      " |  By default, all punctuation is removed, turning the texts into\n",
      " |  space-separated sequences of words\n",
      " |  (words maybe include the `'` character). These sequences are then\n",
      " |  split into lists of tokens. They will then be indexed or vectorized.\n",
      " |  \n",
      " |  `0` is a reserved index that won't be assigned to any word.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ', char_level=False, oov_token=None, document_count=0, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit_on_sequences(self, sequences)\n",
      " |      Updates internal vocabulary based on a list of sequences.\n",
      " |      \n",
      " |      Required before using `sequences_to_matrix`\n",
      " |      (if `fit_on_texts` was never called).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          sequences: A list of sequence.\n",
      " |              A \"sequence\" is a list of integer word indices.\n",
      " |  \n",
      " |  fit_on_texts(self, texts)\n",
      " |      Updates internal vocabulary based on a list of texts.\n",
      " |      \n",
      " |      In the case where texts contains lists,\n",
      " |      we assume each entry of the lists to be a token.\n",
      " |      \n",
      " |      Required before using `texts_to_sequences` or `texts_to_matrix`.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          texts: can be a list of strings,\n",
      " |              a generator of strings (for memory-efficiency),\n",
      " |              or a list of list of strings.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the tokenizer configuration as Python dictionary.\n",
      " |      The word count dictionaries used by the tokenizer get serialized\n",
      " |      into plain JSON, so that the configuration can be read by other\n",
      " |      projects.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A Python dictionary with the tokenizer configuration.\n",
      " |  \n",
      " |  sequences_to_matrix(self, sequences, mode='binary')\n",
      " |      Converts a list of sequences into a Numpy matrix.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          sequences: list of sequences\n",
      " |              (a sequence is a list of integer word indices).\n",
      " |          mode: one of \"binary\", \"count\", \"tfidf\", \"freq\"\n",
      " |      \n",
      " |      # Returns\n",
      " |          A Numpy matrix.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: In case of invalid `mode` argument,\n",
      " |              or if the Tokenizer requires to be fit to sample data.\n",
      " |  \n",
      " |  sequences_to_texts(self, sequences)\n",
      " |      Transforms each sequence into a list of text.\n",
      " |      \n",
      " |      Only top `num_words-1` most frequent words will be taken into account.\n",
      " |      Only words known by the tokenizer will be taken into account.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          sequences: A list of sequences (list of integers).\n",
      " |      \n",
      " |      # Returns\n",
      " |          A list of texts (strings)\n",
      " |  \n",
      " |  sequences_to_texts_generator(self, sequences)\n",
      " |      Transforms each sequence in `sequences` to a list of texts(strings).\n",
      " |      \n",
      " |      Each sequence has to a list of integers.\n",
      " |      In other words, sequences should be a list of sequences\n",
      " |      \n",
      " |      Only top `num_words-1` most frequent words will be taken into account.\n",
      " |      Only words known by the tokenizer will be taken into account.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          sequences: A list of sequences.\n",
      " |      \n",
      " |      # Yields\n",
      " |          Yields individual texts.\n",
      " |  \n",
      " |  texts_to_matrix(self, texts, mode='binary')\n",
      " |      Convert a list of texts to a Numpy matrix.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          texts: list of strings.\n",
      " |          mode: one of \"binary\", \"count\", \"tfidf\", \"freq\".\n",
      " |      \n",
      " |      # Returns\n",
      " |          A Numpy matrix.\n",
      " |  \n",
      " |  texts_to_sequences(self, texts)\n",
      " |      Transforms each text in texts to a sequence of integers.\n",
      " |      \n",
      " |      Only top `num_words-1` most frequent words will be taken into account.\n",
      " |      Only words known by the tokenizer will be taken into account.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          texts: A list of texts (strings).\n",
      " |      \n",
      " |      # Returns\n",
      " |          A list of sequences.\n",
      " |  \n",
      " |  texts_to_sequences_generator(self, texts)\n",
      " |      Transforms each text in `texts` to a sequence of integers.\n",
      " |      \n",
      " |      Each item in texts can also be a list,\n",
      " |      in which case we assume each item of that list to be a token.\n",
      " |      \n",
      " |      Only top `num_words-1` most frequent words will be taken into account.\n",
      " |      Only words known by the tokenizer will be taken into account.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          texts: A list of texts (strings).\n",
      " |      \n",
      " |      # Yields\n",
      " |          Yields individual sequences.\n",
      " |  \n",
      " |  to_json(self, **kwargs)\n",
      " |      Returns a JSON string containing the tokenizer configuration.\n",
      " |      To load a tokenizer from a JSON string, use\n",
      " |      `keras.preprocessing.text.tokenizer_from_json(json_string)`.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          **kwargs: Additional keyword arguments\n",
      " |              to be passed to `json.dumps()`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A JSON string containing the tokenizer configuration.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(help(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create ranges of days WIP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
